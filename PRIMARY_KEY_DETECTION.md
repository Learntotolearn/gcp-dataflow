# ğŸ”‘ MySQLä¸»é”®æ£€æµ‹å®Œæ•´æŒ‡å—

## ğŸ“‹ æ ¸å¿ƒé—®é¢˜

å¦‚ä½•åœ¨ä»£ç ä¸­è‡ªåŠ¨æ£€æµ‹MySQLè¡¨æ˜¯å¦æœ‰ä¸»é”®ï¼Œä»¥ä¾¿é€‰æ‹©æ­£ç¡®çš„åŒæ­¥ç­–ç•¥ï¼Ÿ

## ğŸ” æ£€æµ‹æ–¹æ³•

### æ–¹æ³•1ï¼šæŸ¥è¯¢INFORMATION_SCHEMAï¼ˆæ¨èï¼‰

```python
def has_primary_key(db_host, db_port, db_user, db_pass, db_name, table_name):
    """æ£€æµ‹è¡¨æ˜¯å¦æœ‰ä¸»é”®"""
    conn = mysql.connector.connect(
        host=db_host,
        port=int(db_port),
        user=db_user,
        password=db_pass,
        database=db_name
    )
    cursor = conn.cursor()
    
    # æŸ¥è¯¢ä¸»é”®ä¿¡æ¯
    query = """
    SELECT COLUMN_NAME 
    FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE 
    WHERE TABLE_SCHEMA = %s 
    AND TABLE_NAME = %s 
    AND CONSTRAINT_NAME = 'PRIMARY'
    ORDER BY ORDINAL_POSITION
    """
    
    cursor.execute(query, (db_name, table_name))
    primary_keys = [row[0] for row in cursor.fetchall()]
    
    cursor.close()
    conn.close()
    
    return len(primary_keys) > 0, primary_keys

# ä½¿ç”¨ç¤ºä¾‹
has_pk, pk_columns = has_primary_key('localhost', 3306, 'root', 'password', 'shop1', 'users')
if has_pk:
    print(f"è¡¨æœ‰ä¸»é”®: {pk_columns}")
else:
    print("è¡¨æ²¡æœ‰ä¸»é”®")
```

### æ–¹æ³•2ï¼šä½¿ç”¨SHOW KEYSå‘½ä»¤

```python
def get_primary_keys_show_keys(conn, table_name):
    """ä½¿ç”¨SHOW KEYSæ£€æµ‹ä¸»é”®"""
    cursor = conn.cursor()
    cursor.execute(f"SHOW KEYS FROM {table_name} WHERE Key_name = 'PRIMARY'")
    
    primary_keys = []
    for row in cursor.fetchall():
        # SHOW KEYSè¿”å›æ ¼å¼ï¼š(Table, Non_unique, Key_name, Seq_in_index, Column_name, ...)
        column_name = row[4]  # Column_nameåœ¨ç¬¬5åˆ—ï¼ˆç´¢å¼•4ï¼‰
        seq_in_index = row[3]  # Seq_in_indexåœ¨ç¬¬4åˆ—ï¼ˆç´¢å¼•3ï¼‰
        primary_keys.append((seq_in_index, column_name))
    
    # æŒ‰åºå·æ’åºï¼Œè¿”å›åˆ—ååˆ—è¡¨
    primary_keys.sort(key=lambda x: x[0])
    pk_columns = [col[1] for col in primary_keys]
    
    cursor.close()
    return len(pk_columns) > 0, pk_columns
```

### æ–¹æ³•3ï¼šä½¿ç”¨DESCRIBEå‘½ä»¤

```python
def get_primary_keys_describe(conn, table_name):
    """ä½¿ç”¨DESCRIBEæ£€æµ‹ä¸»é”®"""
    cursor = conn.cursor()
    cursor.execute(f"DESCRIBE {table_name}")
    
    primary_keys = []
    for row in cursor.fetchall():
        # DESCRIBEè¿”å›æ ¼å¼ï¼š(Field, Type, Null, Key, Default, Extra)
        field_name = row[0]
        key_type = row[3]
        
        if key_type == 'PRI':  # Primary Key
            primary_keys.append(field_name)
    
    cursor.close()
    return len(primary_keys) > 0, primary_keys
```

## ğŸ¯ å®Œæ•´çš„è¡¨åˆ†æå™¨

```python
class TableAnalyzer:
    """å®Œæ•´çš„è¡¨ç‰¹å¾åˆ†æå™¨"""
    
    def __init__(self, db_host, db_port, db_user, db_pass):
        self.db_host = db_host
        self.db_port = int(db_port)
        self.db_user = db_user
        self.db_pass = db_pass
    
    def analyze_table(self, db_name, table_name):
        """åˆ†æè¡¨çš„å®Œæ•´ç‰¹å¾"""
        print(f"ğŸ” åˆ†æè¡¨ç‰¹å¾: {db_name}.{table_name}")
        
        conn = mysql.connector.connect(
            host=self.db_host,
            port=self.db_port,
            user=self.db_user,
            password=self.db_pass,
            database=db_name
        )
        
        # 1. æ£€æµ‹ä¸»é”®
        has_pk, primary_keys = self._get_primary_keys(conn, db_name, table_name)
        
        # 2. æ£€æµ‹æ—¶é—´æˆ³å­—æ®µ
        timestamp_fields = self._get_timestamp_fields(conn, db_name, table_name)
        
        # 3. è·å–æ•°æ®é‡
        row_count = self._get_row_count(conn, table_name)
        
        # 4. æ£€æµ‹è¡¨ç±»å‹
        table_type = self._detect_table_type(conn, table_name, primary_keys, timestamp_fields)
        
        conn.close()
        
        analysis = {
            'db_name': db_name,
            'table_name': table_name,
            'has_primary_key': has_pk,
            'primary_keys': primary_keys,
            'timestamp_fields': timestamp_fields,
            'row_count': row_count,
            'table_type': table_type,
            'recommended_strategy': self._recommend_strategy(has_pk, timestamp_fields, table_type)
        }
        
        self._print_analysis(analysis)
        return analysis
    
    def _get_primary_keys(self, conn, db_name, table_name):
        """è·å–ä¸»é”®ä¿¡æ¯"""
        cursor = conn.cursor()
        
        # ä½¿ç”¨INFORMATION_SCHEMAæŸ¥è¯¢ä¸»é”®
        query = """
        SELECT COLUMN_NAME 
        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE 
        WHERE TABLE_SCHEMA = %s 
        AND TABLE_NAME = %s 
        AND CONSTRAINT_NAME = 'PRIMARY'
        ORDER BY ORDINAL_POSITION
        """
        
        cursor.execute(query, (db_name, table_name))
        primary_keys = [row[0] for row in cursor.fetchall()]
        cursor.close()
        
        return len(primary_keys) > 0, primary_keys
    
    def _get_timestamp_fields(self, conn, db_name, table_name):
        """è·å–æ—¶é—´æˆ³å­—æ®µ"""
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ—¶é—´ç›¸å…³å­—æ®µ
        query = """
        SELECT COLUMN_NAME, DATA_TYPE, COLUMN_DEFAULT, IS_NULLABLE
        FROM INFORMATION_SCHEMA.COLUMNS 
        WHERE TABLE_SCHEMA = %s 
        AND TABLE_NAME = %s
        AND (
            DATA_TYPE IN ('timestamp', 'datetime', 'date', 'int', 'bigint')
            OR COLUMN_NAME REGEXP '(time|date|created|updated|modified)'
        )
        ORDER BY ORDINAL_POSITION
        """
        
        cursor.execute(query, (db_name, table_name))
        
        timestamp_fields = []
        for column_name, data_type, column_default, is_nullable in cursor.fetchall():
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ—¶é—´æˆ³å­—æ®µ
            is_timestamp = (
                data_type in ['timestamp', 'datetime', 'date'] or
                any(keyword in column_name.lower() for keyword in 
                    ['time', 'date', 'created', 'updated', 'modified']) or
                (data_type in ['int', 'bigint'] and 'time' in column_name.lower())
            )
            
            if is_timestamp:
                timestamp_fields.append({
                    'name': column_name,
                    'type': data_type,
                    'default': column_default,
                    'nullable': is_nullable == 'YES'
                })
        
        cursor.close()
        return timestamp_fields
    
    def _get_row_count(self, conn, table_name):
        """è·å–è¡¨è¡Œæ•°"""
        cursor = conn.cursor()
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        row_count = cursor.fetchone()[0]
        cursor.close()
        return row_count
    
    def _detect_table_type(self, conn, table_name, primary_keys, timestamp_fields):
        """æ£€æµ‹è¡¨ç±»å‹"""
        # åŸºäºè¡¨åå’Œå­—æ®µç‰¹å¾åˆ¤æ–­è¡¨ç±»å‹
        table_name_lower = table_name.lower()
        
        if any(keyword in table_name_lower for keyword in ['log', 'event', 'history']):
            return 'append_only'  # çº¯è¿½åŠ è¡¨
        elif any(keyword in table_name_lower for keyword in ['user', 'customer', 'product', 'order']):
            return 'business_data'  # ä¸šåŠ¡æ•°æ®è¡¨
        elif any(keyword in table_name_lower for keyword in ['config', 'setting', 'dict']):
            return 'config_data'  # é…ç½®æ•°æ®è¡¨
        else:
            return 'unknown'
    
    def _recommend_strategy(self, has_primary_key, timestamp_fields, table_type):
        """æ¨èåŒæ­¥ç­–ç•¥"""
        if has_primary_key:
            return 'merge'  # æœ‰ä¸»é”®ï¼Œä½¿ç”¨MERGE
        elif timestamp_fields and len(timestamp_fields) > 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆé€‚çš„æ›´æ–°æ—¶é—´å­—æ®µ
            update_fields = [f for f in timestamp_fields 
                           if any(keyword in f['name'].lower() 
                                 for keyword in ['update', 'modified'])]
            if update_fields:
                return 'incremental'  # æœ‰æ›´æ–°æ—¶é—´ï¼Œä½¿ç”¨å¢é‡
        
        if table_type == 'append_only':
            return 'hash_dedup'  # çº¯è¿½åŠ è¡¨ï¼Œä½¿ç”¨å“ˆå¸Œå»é‡
        else:
            return 'full_replace'  # å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨å…¨é‡æ›¿æ¢
    
    def _print_analysis(self, analysis):
        """æ‰“å°åˆ†æç»“æœ"""
        print(f"  ğŸ“Š è¡Œæ•°: {analysis['row_count']:,}")
        print(f"  ğŸ”‘ ä¸»é”®: {analysis['primary_keys'] if analysis['has_primary_key'] else 'æ— '}")
        
        if analysis['timestamp_fields']:
            ts_names = [f['name'] for f in analysis['timestamp_fields']]
            print(f"  ğŸ• æ—¶é—´æˆ³å­—æ®µ: {ts_names}")
        else:
            print(f"  ğŸ• æ—¶é—´æˆ³å­—æ®µ: æ— ")
        
        print(f"  ğŸ“‹ è¡¨ç±»å‹: {analysis['table_type']}")
        print(f"  ğŸ¯ æ¨èç­–ç•¥: {analysis['recommended_strategy']}")
```

## ğŸ¯ å®é™…ä½¿ç”¨ç¤ºä¾‹

```python
def main():
    # åˆ›å»ºè¡¨åˆ†æå™¨
    analyzer = TableAnalyzer('localhost', 3306, 'root', 'password')
    
    # åˆ†æä¸åŒç±»å‹çš„è¡¨
    tables = ['users', 'orders', 'products', 'user_logs']
    
    for table in tables:
        analysis = analyzer.analyze_table('shop1', table)
        
        # æ ¹æ®åˆ†æç»“æœé€‰æ‹©ç­–ç•¥
        if analysis['recommended_strategy'] == 'merge':
            print(f"  âœ… ä½¿ç”¨MERGEç­–ç•¥ï¼Œä¸»é”®: {analysis['primary_keys']}")
        elif analysis['recommended_strategy'] == 'incremental':
            ts_field = analysis['timestamp_fields'][0]['name']
            print(f"  âœ… ä½¿ç”¨å¢é‡åŒæ­¥ï¼Œæ—¶é—´æˆ³å­—æ®µ: {ts_field}")
        elif analysis['recommended_strategy'] == 'hash_dedup':
            print(f"  âœ… ä½¿ç”¨å“ˆå¸Œå»é‡ï¼ˆçº¯è¿½åŠ è¡¨ï¼‰")
        else:
            print(f"  âœ… ä½¿ç”¨å…¨é‡æ›¿æ¢")
        
        print("-" * 50)
```

## ğŸ“Š è¾“å‡ºç¤ºä¾‹

```bash
ğŸ” åˆ†æè¡¨ç‰¹å¾: shop1.users
  ğŸ“Š è¡Œæ•°: 1,234
  ğŸ”‘ ä¸»é”®: ['id']
  ğŸ• æ—¶é—´æˆ³å­—æ®µ: ['created_at', 'updated_at']
  ğŸ“‹ è¡¨ç±»å‹: business_data
  ğŸ¯ æ¨èç­–ç•¥: merge
  âœ… ä½¿ç”¨MERGEç­–ç•¥ï¼Œä¸»é”®: ['id']

ğŸ” åˆ†æè¡¨ç‰¹å¾: shop1.user_logs
  ğŸ“Š è¡Œæ•°: 50,000
  ğŸ”‘ ä¸»é”®: æ— 
  ğŸ• æ—¶é—´æˆ³å­—æ®µ: ['log_time']
  ğŸ“‹ è¡¨ç±»å‹: append_only
  ğŸ¯ æ¨èç­–ç•¥: hash_dedup
  âœ… ä½¿ç”¨å“ˆå¸Œå»é‡ï¼ˆçº¯è¿½åŠ è¡¨ï¼‰

ğŸ” åˆ†æè¡¨ç‰¹å¾: shop1.orders
  ğŸ“Š è¡Œæ•°: 5,678
  ğŸ”‘ ä¸»é”®: ['order_id']
  ğŸ• æ—¶é—´æˆ³å­—æ®µ: ['created_at', 'updated_at']
  ğŸ“‹ è¡¨ç±»å‹: business_data
  ğŸ¯ æ¨èç­–ç•¥: merge
  âœ… ä½¿ç”¨MERGEç­–ç•¥ï¼Œä¸»é”®: ['order_id']
```

## ğŸ”§ é›†æˆåˆ°æ™ºèƒ½åŒæ­¥å·¥å…·

```python
class SmartSyncEngine:
    def __init__(self, params):
        self.params = params
        self.analyzer = TableAnalyzer(
            params['db_host'], params['db_port'],
            params['db_user'], params['db_pass']
        )
        self.client = bigquery.Client(project=params['bq_project'])
    
    def sync_table(self, table_name, db_names):
        """æ™ºèƒ½åŒæ­¥å•ä¸ªè¡¨"""
        print(f"\nğŸš€ å¼€å§‹æ™ºèƒ½åŒæ­¥è¡¨: {table_name}")
        
        # åˆ†æè¡¨ç‰¹å¾ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®åº“ï¼‰
        analysis = self.analyzer.analyze_table(db_names[0], table_name)
        strategy = analysis['recommended_strategy']
        
        # æ ¹æ®ç­–ç•¥æ‰§è¡ŒåŒæ­¥
        if strategy == 'merge':
            return self.sync_with_merge(analysis, db_names)
        elif strategy == 'incremental':
            return self.sync_with_incremental(analysis, db_names)
        elif strategy == 'hash_dedup':
            return self.sync_with_hash_dedup(analysis, db_names)
        else:
            return self.sync_with_full_replace(analysis, db_names)
```

## ğŸŠ æ€»ç»“

æ£€æµ‹MySQLè¡¨æ˜¯å¦æœ‰ä¸»é”®çš„æ–¹æ³•ï¼š

### ğŸ” **æ£€æµ‹æ–¹æ³•**
1. **INFORMATION_SCHEMAæŸ¥è¯¢**ï¼ˆæ¨èï¼‰- æœ€æ ‡å‡†çš„æ–¹æ³•
2. **SHOW KEYSå‘½ä»¤** - ç®€å•ç›´æ¥
3. **DESCRIBEå‘½ä»¤** - æœ€åŸºç¡€çš„æ–¹æ³•

### ğŸ¯ **æ™ºèƒ½ç­–ç•¥é€‰æ‹©**
- **æœ‰ä¸»é”®** â†’ MERGEç­–ç•¥ï¼ˆæ­£ç¡®å¤„ç†UPDATEï¼‰
- **æœ‰æ—¶é—´æˆ³å­—æ®µ** â†’ å¢é‡åŒæ­¥ï¼ˆé«˜æ•ˆï¼‰
- **çº¯è¿½åŠ è¡¨** â†’ å“ˆå¸Œå»é‡ï¼ˆå®‰å…¨ï¼‰
- **å…¶ä»–æƒ…å†µ** â†’ å…¨é‡æ›¿æ¢ï¼ˆå¯é ï¼‰

è¿™æ ·æˆ‘ä»¬å°±èƒ½æ ¹æ®è¡¨çš„å®é™…ç‰¹å¾ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„åŒæ­¥ç­–ç•¥ï¼Œé¿å…å“ˆå¸Œå»é‡å¯¼è‡´çš„é‡å¤æ•°æ®é—®é¢˜ï¼ğŸ¯